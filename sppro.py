import streamlit as st
from transformers import pipeline
from datasets import load_dataset
import torch
import soundfile as sf
import io
import numpy as np

# ---------------------- Page Config ----------------------
st.set_page_config(page_title="Arabic Neural TTS", page_icon="ğŸ—£ï¸", layout="centered")

# ---------------------- Title and Introduction ----------------------
st.title("ğŸ—£ï¸ Arabic Neural TTS Demo")
st.markdown("Welcome to the **Arabic Text-to-Speech** app using `MBZUAI/speecht5_tts_clartts_ar`. Enter Arabic text and listen to the generated audio.")
st.markdown("---")

# ---------------------- Load TTS Pipeline and Speaker Embeddings ----------------------
@st.cache_resource
def get_tts_pipeline():
    device = 0 if torch.cuda.is_available() else -1
    return pipeline("text-to-speech", "MBZUAI/speecht5_tts_clartts_ar", device=device)

@st.cache_resource
def load_speaker_embeddings():
    return load_dataset("herwoww/arabic_xvector_embeddings", split="validation")

def get_random_speaker_embedding(ds):
    idx = np.random.randint(0, len(ds))
    return torch.tensor(ds[idx]["speaker_embeddings"]).unsqueeze(0)

def get_first_speaker_embedding(ds):
    return torch.tensor(ds[0]["speaker_embeddings"]).unsqueeze(0)

# ---------------------- Sidebar ----------------------
with st.sidebar:
    st.header("ğŸ“˜ Project Info")
    st.markdown("**Model**: MBZUAI/speecht5_tts_clartts_ar")
    st.markdown("**Speaker embeddings**: x-vector")
    st.markdown("**Frameworks**: ğŸ¤— Transformers, Streamlit")

    st.markdown("---")
    st.subheader("ğŸ‘¤ Developer Info")
    st.markdown("**Name**:BENAICHA Mohamed Etaib")  
    st.markdown("[ğŸ“Š My Kaggle](https://www.kaggle.com/mohamedtaib)")  
    st.markdown("[ğŸ”— My LinkedIn](https://www.linkedin.com/in/mohamed-etaib-benaicha-757600254/)")  

    st.markdown("---")
    st.markdown("ğŸ’¡ Tip: Try random speaker voices!")


# ---------------------- Input Section ----------------------
st.subheader("âœï¸ Input Arabic Text")
sample_phrases = [
    "Ù…Ø±Ø­Ø¨Ù‹Ø§ Ø¨ÙƒÙ… ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØµÙˆØªÙŠ",
    "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØºÙŠØ± Ø§Ù„Ø¹Ø§Ù„Ù… Ù…Ù† Ø­ÙˆÙ„Ù†Ø§",
    "ØªØ¹Ù„Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙŠÙ…Ù†Ø­Ùƒ ÙØ±ØµØ© Ø¬Ø¯ÙŠØ¯Ø©",
    "Ø§Ù„ØµÙˆØª Ø§Ù„Ø¨Ø´Ø±ÙŠ ÙŠØ­Ù…Ù„ Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ù…Ø´Ø§Ø¹Ø±",
    "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø¶Ø±ÙˆØ±ÙŠØ© Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø°ÙƒÙŠØ©"
]

ds = load_speaker_embeddings()

col1, col2 = st.columns([3, 2])

with col1:
    text_input = st.text_area("Ø§ÙƒØªØ¨ Ø¬Ù…Ù„Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", height=150)

with col2:
    selected = st.selectbox("Ø£Ùˆ Ø§Ø®ØªØ± Ø¬Ù…Ù„Ø© Ø¬Ø§Ù‡Ø²Ø©:", [""] + sample_phrases)
    if selected:
        text_input = selected

# ---------------------- Voice Option ----------------------
st.subheader("ğŸ™ï¸ Speaker Voice Options")
use_random_voice = st.checkbox("ğŸ² Use random speaker voice", value=False)

# ---------------------- Synthesize and Play ----------------------
if st.button("ğŸ”Š Generate Audio"):
    if not text_input.strip():
        st.warning("ğŸš« Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.")
    else:
        with st.spinner("ğŸ§ Synthesizing speech..."):
            tts = get_tts_pipeline()
            spk_emb = get_random_speaker_embedding(ds) if use_random_voice else get_first_speaker_embedding(ds)
            result = tts(text_input, forward_params={"speaker_embeddings": spk_emb})
            audio, sr = result["audio"], result["sampling_rate"]

            # Save to buffer
            buf = io.BytesIO()
            sf.write(buf, audio, samplerate=sr, format='WAV')
            buf.seek(0)

            st.success("âœ… Audio generated!")
            st.audio(buf.read(), format='audio/wav')
            st.download_button("â¬‡ï¸ Download Audio", data=buf, file_name="arabic_tts.wav", mime="audio/wav")

# ---------------------- Extra Info ----------------------
with st.expander("â„¹ï¸ What is SpeechT5 and x-vectors?"):
    st.markdown("""
    - **SpeechT5** is a model by Microsoft designed for tasks like text-to-speech and automatic speech recognition.
    - It takes both text and a speaker embedding to generate speech that mimics a specific voice.
    - **x-vectors** are compact representations of speaker identity used to personalize TTS output.
    """)

# ---------------------- Feedback ----------------------
st.markdown("---")
st.subheader("â­ Rate the Voice Quality")
rating = st.slider("ÙƒÙŠÙ ØªÙ‚ÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØªØŸ", 1, 5, value=3)
if st.button("ğŸ“© Submit Feedback"):
    st.success(f"ğŸ‰ Ø´ÙƒØ±Ø§Ù‹! ØªÙ… ØªØ³Ø¬ÙŠÙ„ ØªÙ‚ÙŠÙ…Ùƒ: {rating}/5")

# ---------------------- Footer ----------------------
st.markdown("---")
st.caption("Built with ğŸ¤— Transformers & Streamlit | Â© 2025 UniversitÃ© de Blida 1")
